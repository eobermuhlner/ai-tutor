# AI Tutor Pedagogical Test Harness Configuration

# API Configuration
apiBaseUrl: http://localhost:8080
apiUsername: demo
apiPassword: demo

# Judge Configuration (LLM-as-judge)
# Supports multiple AI providers: openai, azure-openai, ollama
judgeProvider: ollama          # AI provider (openai | azure-openai | ollama)
judgeModel: granite3.2:8b      # Model name
judgeTemperature: 0.2          # Temperature (0.0-2.0)

# Optional: Override API configuration (defaults to environment variables)
# judgeApiKey: sk-...          # API key (or use OPENAI_API_KEY / AZURE_OPENAI_API_KEY / TESTHARNESS_JUDGE_API_KEY env var)
# judgeApiEndpoint: https://... # API endpoint (or use provider defaults / TESTHARNESS_JUDGE_API_ENDPOINT)
# judgeDeploymentName: gpt-4o   # Azure OpenAI deployment name (or use AZURE_OPENAI_DEPLOYMENT / TESTHARNESS_JUDGE_DEPLOYMENT_NAME)

# Examples for different providers:
#
# OpenAI (default):
#   judgeProvider: openai
#   judgeModel: gpt-4o
#   # Uses OPENAI_API_KEY environment variable
#
# Azure OpenAI:
#   judgeProvider: azure-openai
#   judgeModel: gpt-4o  # Not used for Azure (uses deployment name)
#   judgeDeploymentName: my-gpt4-deployment
#   judgeApiEndpoint: https://myresource.openai.azure.com
#   # Uses AZURE_OPENAI_API_KEY environment variable
#
# Ollama (local):
#   judgeProvider: ollama
#   judgeModel: llama3
#   judgeApiEndpoint: http://localhost:11434/api/chat
#   # No API key needed for local Ollama

# Test Scenarios
scenariosPath: scenarios
scenarioFilter: all

# Reporting
reportsOutputDir: test-reports

# Test Execution
passThreshold: 70.0
maxConcurrentSessions: 3
requestTimeoutMs: 120000

# Rate Limiting (helps avoid OpenAI API quota/rate limit errors)
delayBetweenRequestsMs: 1000    # Delay between consecutive requests (default: 1000ms = 1 req/sec)
maxRetries: 3                   # Maximum number of retries for 429/503 errors
retryBackoffMultiplier: 2.0     # Exponential backoff multiplier (delay = 1000 * multiplier^attempt)
